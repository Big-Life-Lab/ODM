# -*- coding: utf-8 -*-
"""create_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rIggOMOLnLdGEojAUbe1cpdmI794gr2I
"""

import csv
import json
import os
import re

import numpy as np  # pylint: disable=import-error
import pandas as pd  # pylint: disable=import-error
from numpy import nan  # pylint: disable=import-error
from pandas import Timestamp  # pylint: disable=import-error

#import loop_through_tables # pylint: disable=import-error
from loop_through_tables import loop_through_tables

dataset = {
    "Sample": [
        {
            "collection": "mooreSw",
            "dateTime": Timestamp("2021-02-01 21:00:00"),
            "dateTimeEnd": Timestamp("2021-01-29 21:00:00"),
            "dateTimeStart": Timestamp("2021-02-01 21:00:00"),
            "fieldSampleTempC": 15,
            "sampleID": "Sample S100",
            "sizeL": 8,
            "storageTempC": 16,
            "type": "swrSed",
        },
        {
            "collection": "cpTP24h",
            "dateTime": Timestamp("2021-01-25 21:00:00"),
            "dateTimeEnd": Timestamp("2021-01-24 08:00:00"),
            "dateTimeStart": Timestamp("2021-01-24 08:00:00"),
            "fieldSampleTempC": 17,
            "sampleID": "Sample S106",
            "sizeL": 2,
            "storageTempC": 18,
            "type": "pSludge",
        },
        {
            "collection": "grb",
            "dateTime": Timestamp("2021-01-28 21:00:00"),
            "dateTimeEnd": Timestamp("2021-02-01 08:00:00"),
            "dateTimeStart": Timestamp("2021-01-27 08:00:00"),
            "fieldSampleTempC": 18,
            "sampleID": "Sample S107",
            "sizeL": 10,
            "storageTempC": 22,
            "type": "rawWW",
        },
    ],
    "WWMeasure": [
        {
            "analysisDate": Timestamp("2021-01-25 00:00:00"),
            "reportDate": Timestamp("2021-02-06 00:00:00"),
            "type": "covN2",
            "uWwMeasureID": "Measure WW100",
            "unit": "gcM",
            "unitOther": "gcMcovN2",
            "value": 145000,
        },
        {
            "analysisDate": Timestamp("2021-01-28 00:00:00"),
            "reportDate": Timestamp("2021-01-25 00:00:00"),
            "type": "covN2",
            "uWwMeasureID": "Measure WW100",
            "unit": "gcMl",
            "unitOther": "gcMcovN1",
            "value": 16000,
        },
        {
            "analysisDate": Timestamp("2021-02-06 00:00:00"),
            "reportDate": Timestamp("2021-03-06 00:00:00"),
            "type": "nPMMoV",
            "uWwMeasureID": "Measure WW100",
            "unit": "gcMl",
            "unitOther": "gcmnPMMoV",
            "value": 98000,
        },
    ],
}

# User requested organization:
organization = "PHAC"


def create_dataset(rules: list, data: dict = {}, org: str = '') -> dict:
  """Filters data and returns filtered data and shared summary in dictionary.
  
  The function will filter only those rules from rules list that correspond 
  to the particular organization user has requested and create a list 
  org_rules. It will iterate through each rule in org_rule to the filter 
  the user data. Return is a list of two dictionaries. One dictionary is
  the filtered data. Other is the current_rule_summary that contains details 
  about entities and rows removed.

  Parameters:
      rules(list): list of rule dictionaries
      data(dict): user data to be filtered
      org(str): name of the requested organization
  Returns:
      list: list of two dictionaries with filtered data & entities removed
  """
  # Load the variables.csv file to get the primary key values for each variables in the data
  variables = pd.read_csv('Variables.csv', delimiter=',')

  #Fetch all the names of tables in the ODM
  original_tables = list(variables['tableName'].unique()) 

  #For each table, create a list of dictionaries that contains the metadata 
  # primary, foreign keys, variable type information for each variable
  datatype_dict = {}
  for table in original_tables:
    datatype_dict[table] = \
        variables[variables['tableName']==table].to_dict('records')

  # filtered_data is the copy of the data provided by the user. 
  # It is returned to the user after filter.
  filtered_data = data.copy()

  #Store original data from the dataset dictionary in variable origina_data
  original_data = data.copy()

  # Check whether the given organization is part of current rule, then add 
  # the rule to a list 'org_rule'. Each rule is a dictionary
  org_rule = []

  for rule_org in rules:
    if ';' in rule_org['sharedWith']:
      list_of_organizations = rule_org['sharedWith'].split(';')
    else: 
      list_of_organizations = [rule_org['sharedWith']]
    if org in list_of_organizations:
      org_rule.append(rule_org)

  # Create a copy of original dataset dictionary.
  # This is updated for each iteration to detect rows removed. 
  updated_data_dict = original_data.copy()

# returned_data is the dictionary with two keys returned to user: 
  # one key containing the filtered_data and the other with the removed data
  returned_data: dict = {}
  sharing_summary = []

  #ITTERATE THROUGH EACH RULE
  for rule in org_rule:

    # Create a dictionary that will contain the entities and data removed.
    current_rule_summary = {'entities_filtered': [], 'rule_id':rule['ruleID']}
    
    # Create an empty dataframe only if it does not exist 
    # This dataframe is used to detect rows removed in each iteration.
    try:
      original_table_data_copy # type: ignore
    except NameError:
      original_table_data_copy = pd.DataFrame()

     #'filtered_data' is the dictionary with filtered data 
     # calls the function 'loop_through_tables' to iterate through each table
     # and finally returns the 'filtered_data' and the 'current_rule_summary'.
    filtered_data, original_table_data_copy, current_rule_summary = \
        loop_through_tables(rule, datatype_dict, filtered_data, original_data, \
            current_rule_summary, original_table_data_copy, updated_data_dict)
    sharing_summary.append(current_rule_summary)
  for tables, data in filtered_data.items():
      for row in data:
          for variable, value in row.items():
              if value == nan:
                  value = 'null'
      

  returned_data['filtered_data'] = filtered_data
  returned_data['sharing_summary'] = sharing_summary
  return returned_data













